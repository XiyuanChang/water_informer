{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import torch\n",
    "from model import model as module_model\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import dataset\n",
    "from mytransform import MeanStdNormalize, MinMaxNormalize, MeanStdDeNormalize, MinMaxDeNormalize, LogNormalize, LogDeNormalize\n",
    "import json\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "np.random.seed(42)\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/model_agnostic/Multioutput%20Regression%20SHAP.html#Get-SHAP-Values-and-Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = \"saved_deepOnetC_31/models/Mnist_LeNet/0625_143733/config.json\"\n",
    "# state_path = \"saved_deepOnetC_31/models/Mnist_LeNet/0625_143733/checkpoint-epoch200.pth\"\n",
    "# state_path = \"saved_deepOnetC_31/models/Mnist_LeNet/0625_143733/best_target_state_dict.pth\"\n",
    "config = \"saved_deepOnetC_105/models/Mnist_LeNet/0811_141611/config.json\"\n",
    "state_path = \"saved_deepOnetC_105/models/Mnist_LeNet/0811_141611/best_target_state_dict.pth\"\n",
    "\n",
    "config = json.load(open(config))\n",
    "# config = ConfigParser.from_args(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_obj(config, name, module, *args, **kwargs):\n",
    "    module_name = config[name]['type']\n",
    "    module_args = dict(config[name]['args'])\n",
    "    assert all([k not in module_args for k in kwargs]), 'Overwriting kwargs given in config file is not allowed'\n",
    "    \n",
    "    module_args.update(kwargs)\n",
    "    return getattr(module, module_name)(*args, **module_args)\n",
    "\n",
    "activation = getattr(nn, config[\"activation\"])\n",
    "trunk = init_obj(config, 'trunk', module_model, activation=activation)\n",
    "branch = init_obj(config, 'branch', module_model, activation=activation)\n",
    "z_net = init_obj(config, 'z_net', module_model, activation=activation)\n",
    "\n",
    "if config['arch_name'] == 'TriDeepONet':\n",
    "    model = module_model.TriDeepONet(trunk, branch, z_net)\n",
    "elif config['arch_name'] == 'DeepONet':\n",
    "    model = module_model.DeepONet(trunk, branch)\n",
    "model = model.cuda()\n",
    "# model.load_state_dict(torch.load(state_path)['state_dict'])\n",
    "model.load_state_dict(torch.load(state_path)[5])\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict = {\n",
    "    \"ClimateDatasetV2A\": \"split_datesA.txt\",\n",
    "    \"ClimateDatasetV2B\": \"split_datesB.txt\",\n",
    "    \"ClimateDatasetV2C\": \"split_datesC.txt\",\n",
    "}\n",
    "train_dates, test_dates = [], []\n",
    "split_path = split_dict[config['dataset']]\n",
    "with open(os.path.join(\"../climate_washed\", split_path)) as f:\n",
    "    for line in f.readlines():\n",
    "        date, mode = line.split(\" \")\n",
    "        date = date.strip()\n",
    "        mode = mode.strip()\n",
    "        \n",
    "        if mode == 'train':\n",
    "            train_dates.append(date)\n",
    "        elif mode == 'test':\n",
    "            test_dates.append(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_class = getattr(dataset, config['dataset'])\n",
    "trainset = data_class(\"../climate_washed\", config['normalize'], split=\"train\", x_feature=config['x_feature'], y_feature=config['y_feature'])\n",
    "stats = trainset.get_stats()\n",
    "testset = data_class(\"../climate_washed\", config['normalize'], split=\"test\", stats=stats, x_feature=config['x_feature'], y_feature=config['y_feature'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import from_numpy\n",
    "test_target = testset.targets\n",
    "test_station, test_target, test_temporal = [], [], []\n",
    "\n",
    "for idx, targets in enumerate(testset.targets):\n",
    "    station = testset.stations[idx]\n",
    "    target = testset.targets[idx]\n",
    "    temporal = testset.temporal[idx]\n",
    "    test_station.append(station)\n",
    "    test_target.append(target)\n",
    "    test_temporal.append(temporal)\n",
    "\n",
    "test_station = from_numpy(np.concatenate(test_station))\n",
    "test_target = from_numpy(np.concatenate(test_target))\n",
    "test_temporal = from_numpy(np.concatenate(test_temporal))\n",
    "print(test_station.shape, test_target.shape, test_temporal.shape)\n",
    "\n",
    "for i in range(10, 21):\n",
    "    print(i,\",\", ((~torch.isnan(test_target)).sum(dim=1)==i).sum().item())\n",
    "\n",
    "# find the index where (~torch.isnan(target)).sum(dim=1)==20\n",
    "test_valid_index = ((~torch.isnan(test_target)).sum(dim=1)>=15).nonzero().squeeze()\n",
    "print(test_valid_index.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = trainset.targets\n",
    "print(target.shape)\n",
    "print(\"Valid y number, count\")\n",
    "for i in range(10, 21):\n",
    "    print(i,\",\", ((~torch.isnan(target)).sum(dim=1)==i).sum().item())\n",
    "\n",
    "# find the index where (~torch.isnan(target)).sum(dim=1)==20\n",
    "valid_index = ((~torch.isnan(target)).sum(dim=1)>=19).nonzero().squeeze()\n",
    "print(valid_index.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['normalize'] == \"MinMaxNormalize\":\n",
    "    temporal_transform = MinMaxNormalize(\n",
    "        stats['temporal']['max'],\n",
    "        stats['temporal']['min']\n",
    "    )\n",
    "    station_transform = MinMaxNormalize(\n",
    "        stats['station']['max'],\n",
    "        stats['station']['min']\n",
    "    )\n",
    "elif config['normalize'] == \"MeanStdNormalize\":\n",
    "    temporal_transform = MeanStdNormalize(\n",
    "        stats['temporal']['mean'],\n",
    "        stats['temporal']['variance']\n",
    "    )\n",
    "    station_transform = MeanStdNormalize(\n",
    "        stats['station']['mean'],\n",
    "        stats['station']['variance']\n",
    "    )\n",
    "target_transform = LogNormalize(\n",
    "    stats['target']['10th'],\n",
    "    stats['target']['90th']\n",
    ")\n",
    "target_detransform = LogDeNormalize(\n",
    "    stats['target']['10th'],\n",
    "    stats['target']['90th']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x: np.ndarray):\n",
    "    temporal = x[:, :len(config['x_feature'])].astype(np.float32)\n",
    "    station = x[:, len(config['x_feature']):].astype(np.float32)\n",
    "    \n",
    "    temporal = torch.from_numpy(temporal)\n",
    "    station = torch.from_numpy(station)\n",
    "    \n",
    "    temporal = temporal_transform(temporal).cuda()\n",
    "    station = station_transform(station).cuda()\n",
    "    \n",
    "    prediction = model(temporal, station)\n",
    "    prediction = target_detransform(prediction)\n",
    "    \n",
    "    prediction_df = pd.DataFrame(prediction.cpu().detach().numpy(), columns=[config['y_feature']])\n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations, temporal = trainset.stations, trainset.temporal\n",
    "train_data = torch.cat([temporal, stations], dim=1)\n",
    "\n",
    "train_data = train_data[valid_index].numpy()\n",
    "# randomly select 5000 samples from train data\n",
    "indices = np.random.choice(train_data.shape[0], 400, replace=False)\n",
    "# train_data = train_data[indices].numpy()\n",
    "train_data = train_data[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id = \"01054200\"\n",
    "\n",
    "temporal_df = pd.read_csv(f\"../climate_washed/{station_id}.csv\")\n",
    "stations = pd.read_csv(f\"../climate_washed/static_filtered.csv\", dtype={\"STAID\": str})\n",
    "stations[\"STAID\"] = stations[\"STAID\"].apply(lambda x: str(x).zfill(8))\n",
    "station_df = stations[stations[\"STAID\"] == station_id].iloc[:, 1:]\n",
    "\n",
    "# load train data\n",
    "train_temporal_df = temporal_df[temporal_df['Date'].isin(train_dates)].reset_index(drop=True)\n",
    "train_temporal_df = train_temporal_df[config['x_feature']]\n",
    "station_df_broadcast = pd.DataFrame(np.repeat(station_df.values, train_temporal_df.shape[0], axis=0))\n",
    "station_df_broadcast.columns = station_df.columns\n",
    "\n",
    "# train_df = pd.concat([train_temporal_df, station_df_broadcast], axis=1)\n",
    "train_df = train_temporal_df.join(station_df_broadcast)\n",
    "# print(train_temporal_df.head)\n",
    "# print(station_df_broadcast.head)\n",
    "# print(train_df.head)\n",
    "\n",
    "\n",
    "# load test data\n",
    "test_temporal_df = temporal_df[temporal_df['Date'].isin(test_dates)].reset_index(drop=True)\n",
    "test_temporal_df = test_temporal_df[config['x_feature']]\n",
    "station_df_broadcast = pd.DataFrame(np.repeat(station_df.values, test_temporal_df.shape[0], axis=0))\n",
    "station_df_broadcast.columns = station_df.columns\n",
    "# test_df = pd.concat([test_temporal_df, station_df_broadcast], axis=1)\n",
    "test_df = test_temporal_df.join(station_df_broadcast)\n",
    "# print(test_temporal_df.shape)\n",
    "# print(station_df_broadcast.shape)\n",
    "# print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = shap.KernelExplainer(predict, train_df)\n",
    "print(train_data.shape)\n",
    "explainer = shap.KernelExplainer(predict, train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(train_data, nsamples=200)\n",
    "# shap_values = explainer(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_labels = config['y_feature']\n",
    "\n",
    "# Create a list of tuples so that the index of the label is what is returned\n",
    "tuple_of_labels = list(zip(list_of_labels, range(len(list_of_labels))))\n",
    "\n",
    "# Create a widget for the labels and then display the widget\n",
    "current_label = widgets.Dropdown(\n",
    "    options=tuple_of_labels, value=0, description=\"Select Label:\"\n",
    ")\n",
    "\n",
    "# Display the dropdown list (Note: access index value with 'current_label.value')\n",
    "current_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = shap_values[:, :, current_label.value].mean(0)\n",
    "\n",
    "# pair the mean with test_df.columns, then rank them in descending order of absolute value\n",
    "mean = pd.Series(mean, index=test_df.columns)\n",
    "mean = mean.abs().sort_values(ascending=True)\n",
    "\n",
    "\n",
    "# bar plot the mean impact of each feature, the bar names are the feature names\n",
    "# plot the top 40 features only\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 20))\n",
    "mean.plot(kind='barh')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Current Label Shown: {list_of_labels[current_label.value]}\\n\")\n",
    "\n",
    "# shap.plots.violin(\n",
    "#     # shap_values[:, :, current_label.value], \n",
    "#     shap_values,\n",
    "#     feature_names=test_df.columns,\n",
    "#     max_display=41\n",
    "# )\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    # shap_values[:, :, current_label.value], \n",
    "    features=test_df.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriDeepExplain(module_model.TriDeepONet):\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x).float().cuda()\n",
    "        u = x[:, :len(config['x_feature'])]\n",
    "        y = x[:, len(config['x_feature']):]\n",
    "\n",
    "        u_out = self.u_net(u)\n",
    "        # u_out = F.dropout(u_out, p=0.25)\n",
    "        y_out = self.y_net(y)\n",
    "        # y_out = F.dropout(y_out, p=0.25)\n",
    "        outputs = u_out * y_out\n",
    "        #outputs = F.dropout(outputs, p=0.25)\n",
    "        outputs = self.z_net(outputs)\n",
    "\n",
    "        # return target_detransform(outputs)\n",
    "        return outputs\n",
    "\n",
    "class DeepExplain(module_model.DeepONet):\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x).float().cuda()\n",
    "        u = x[:, :len(config['x_feature'])]\n",
    "        y = x[:, len(config['x_feature']):]\n",
    "\n",
    "        u_out = self.u_net(u)\n",
    "        y_out = self.y_net(y)\n",
    "\n",
    "        outputs = torch.sum(u_out * y_out, dim=-1)\n",
    "        # return target_detransform(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = getattr(nn, config[\"activation\"])\n",
    "trunk = init_obj(config, 'trunk', module_model, activation=activation)\n",
    "branch = init_obj(config, 'branch', module_model, activation=activation)\n",
    "z_net = init_obj(config, 'z_net', module_model, activation=activation)\n",
    "\n",
    "if config['arch_name'] == 'TriDeepONet':\n",
    "    model = TriDeepExplain(trunk, branch, z_net)\n",
    "elif config['arch_name'] == 'DeepONet':\n",
    "    model = DeepExplain(trunk, branch)\n",
    "\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load(state_path)[5])\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations, temporal = trainset.stations, trainset.temporal\n",
    "stations = station_transform(stations)\n",
    "temporal = temporal_transform(temporal)\n",
    "train_data = torch.cat([temporal, stations], dim=1)\n",
    "\n",
    "# randomly select 5000 samples from train data\n",
    "train_data = train_data[valid_index].numpy()\n",
    "indices = np.random.choice(train_data.shape[0], 10000, replace=False)\n",
    "# train_data = train_data[indices].numpy()\n",
    "train_data = train_data[indices]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.cat([test_temporal, test_station], dim=1).float()\n",
    "test_data = test_data[test_valid_index].numpy()\n",
    "\n",
    "indices = np.random.choice(test_data.shape[0], 4500, replace=False)\n",
    "test_data = test_data[indices]\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert train df to pytorch tensor\n",
    "# train_data = torch.from_numpy(train_df.values).float().cuda()\n",
    "\n",
    "deep_explainer = shap.DeepExplainer(\n",
    "    model,\n",
    "    torch.from_numpy(train_data).cuda(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_shap_values = deep_explainer.shap_values(\n",
    "    # torch.from_numpy(train_data).cuda(),\n",
    "    torch.from_numpy(test_data).cuda(), \n",
    "    check_additivity=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_labels = config['y_feature']\n",
    "\n",
    "# Create a list of tuples so that the index of the label is what is returned\n",
    "tuple_of_labels = list(zip(list_of_labels, range(len(list_of_labels))))\n",
    "\n",
    "# Create a widget for the labels and then display the widget\n",
    "current_label = widgets.Dropdown(\n",
    "    options=tuple_of_labels, value=0, description=\"Select Label:\"\n",
    ")\n",
    "\n",
    "# Display the dropdown list (Note: access index value with 'current_label.value')\n",
    "current_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(20):\n",
    "#     deep_mean = deep_shap_values[:, :, i].mean(0)\n",
    "\n",
    "#     # pair the mean with test_df.columns, then rank them in descending order of absolute value\n",
    "#     deep_mean = pd.Series(deep_mean, index=test_df.columns)\n",
    "#     deep_mean = deep_mean.abs().sort_values(ascending=True)\n",
    "\n",
    "#     # bar plot the mean impact of each feature, the bar names are the feature names\n",
    "#     # plot in descending order\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     plt.figure(figsize=(15, 20))\n",
    "#     deep_mean.plot(kind='barh')\n",
    "#     plt.title(config['y_feature'][i])\n",
    "#     plt.savefig(\"shap_plot/\"+config['y_feature'][i]+\".png\")\n",
    "deep_mean = np.abs(deep_shap_values[:, :, current_label.value]).mean(0)\n",
    "\n",
    "# pair the mean with test_df.columns, then rank them in descending order of absolute value\n",
    "deep_mean = pd.Series(deep_mean, index=test_df.columns)\n",
    "deep_mean = deep_mean.abs().sort_values(ascending=True)\n",
    "\n",
    "# bar plot the mean impact of each feature, the bar names are the feature names\n",
    "# plot in descending order\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15, 20))\n",
    "deep_mean.plot(kind='barh')\n",
    "plt.title(config['y_feature'][current_label.value])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Current Label Shown: {list_of_labels[current_label.value]}\\n\")\n",
    "\n",
    "shap.plots.violin(\n",
    "    deep_shap_values[:, :, current_label.value], \n",
    "    feature_names=test_df.columns,\n",
    "    max_display=105\n",
    ")\n",
    "# shap.summary_plot(\n",
    "#     deep_shap_values[:, :, current_label.value], features=test_df.columns\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"shap_value_6000.npy\", deep_shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(\n",
    "    deep_shap_values[:, :, current_label.value],\n",
    "    max_display=30,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriDeepExplain(module_model.TriDeepONet):\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x).float().cuda()\n",
    "        u = x[:, :len(config['x_feature'])]\n",
    "        y = x[:, len(config['x_feature']):]\n",
    "\n",
    "        u_out = self.u_net(u)\n",
    "        # u_out = F.dropout(u_out, p=0.25)\n",
    "        y_out = self.y_net(y)\n",
    "        # y_out = F.dropout(y_out, p=0.25)\n",
    "        outputs = u_out * y_out\n",
    "        #outputs = F.dropout(outputs, p=0.25)\n",
    "        outputs = self.z_net(outputs)[..., 5]\n",
    "\n",
    "        # return target_detransform(outputs)\n",
    "        return outputs.detach().cpu().numpy()\n",
    "\n",
    "class DeepExplain(module_model.DeepONet):\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x).float().cuda()\n",
    "        u = x[:, :len(config['x_feature'])]\n",
    "        y = x[:, len(config['x_feature']):]\n",
    "\n",
    "        u_out = self.u_net(u)\n",
    "        y_out = self.y_net(y)\n",
    "\n",
    "        outputs = torch.sum(u_out * y_out, dim=-1).detach().cpu().numpy()\n",
    "        # return target_detransform(outputs)\n",
    "        return outputs\n",
    "    \n",
    "activation = getattr(nn, config[\"activation\"])\n",
    "trunk = init_obj(config, 'trunk', module_model, activation=activation)\n",
    "branch = init_obj(config, 'branch', module_model, activation=activation)\n",
    "z_net = init_obj(config, 'z_net', module_model, activation=activation)\n",
    "\n",
    "if config['arch_name'] == 'TriDeepONet':\n",
    "    model = TriDeepExplain(trunk, branch, z_net)\n",
    "elif config['arch_name'] == 'DeepONet':\n",
    "    model = DeepExplain(trunk, branch)\n",
    "\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load(state_path)[5])\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "stations, temporal = trainset.stations, trainset.temporal\n",
    "train_data = torch.cat([temporal, stations], dim=1)\n",
    "\n",
    "train_data = train_data[valid_index].numpy()\n",
    "# train_data = train_data.numpy()\n",
    "\n",
    "# randomly select 5000 samples from train data\n",
    "# indices = np.random.choice(train_data.shape[0], 20000, replace=False)\n",
    "# train_data = train_data[indices].numpy()\n",
    "# train_data = train_data[indices]\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explainer = lime.lime_tabular.LimeTabularExplainer(train_data, feature_names=test_df.columns, mode=\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "num = 12235\n",
    "values = np.zeros([num, train_data.shape[1]])\n",
    "\n",
    "for i in tqdm(range(num)):\n",
    "    exp = lime_explainer.explain_instance(train_data[i], model.forward, num_features=train_data.shape[1])\n",
    "    result = exp.as_map()[0]\n",
    "    for key, value in result:\n",
    "        values[i, key] = value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.show_in_notebook(show_table=True)\n",
    "exp.show_in_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.abs(values).mean(axis=0)\n",
    "# pair the means with test_df.columns, then rank them in descending order of absolute value\n",
    "means = pd.Series(means, index=test_df.columns)\n",
    "means = means.abs().sort_values(ascending=True)\n",
    "# find the rows where index is in config['x_feature']\n",
    "# means = means.loc[config['x_feature']].sort_values(ascending=True)\n",
    "\n",
    "# plot the mean impact of each feature, the bar names are the feature names\n",
    "# plot in descending order\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 20))\n",
    "means.plot(kind='barh')\n",
    "plt.title(\"00600\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nature",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
